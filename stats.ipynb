{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd, os, numpy as np\n",
    "#from scipy.stats import skew, kurtosis, entropy\n",
    "#from sklearn.mixture import GaussianMixture as gmm\n",
    "#import networkx.algorithms.community as nx_comm\n",
    "##import networkx as nx\n",
    "#import json as js\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style({'axes.facecolor': 'white',\n",
    "         'axes.edgecolor': 'black',\n",
    "        'axes.grid': False,\n",
    "        'axes.spines.right': False,\n",
    "        'axes.spines.top': False,\n",
    "        'figure.facecolor':\"white\",\n",
    "        'axes.labelcolor': '.15',\n",
    "         'grid.color': 'white',\n",
    "         'grid.linestyle': '-',\n",
    "         'text.color': '.15',\n",
    "         'xtick.color': '.15',\n",
    "         'ytick.color': '.15',\n",
    "        'patch.edgecolor': 'white',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/N/slate/harryan/sim_data/\"\n",
    "TAR_DIR = \"/N/slate/harryan/sim_data_extra/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_files = os.listdir(TAR_DIR + \"entropy_ts\")\n",
    "N_files = sorted([i for i in ets_files if (\"N0\" in i or f\"N{str(1)}\" in i) and \"eta5\" in i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"#abc9c8\",\n",
    "    \"#72aeb6\",\n",
    "    \"#4692b0\",\n",
    "    \"#2f70a1\",\n",
    "    \"#134b73\",\n",
    "    \"#0a3351\"\n",
    "    ]\n",
    "#marker_styles = ['o', 's', '^', '*', 'D', 'P']\n",
    "#ets_files = os.listdir(TAR_DIR + \"entropy_ts\")\n",
    "#N_files = sorted([i for i in ets_files if (\"N0\" in i or f\"N{str(n)}\" in i) and \"eta5\" in i])\n",
    "def plot_entropy(n, ax, include_legend=False): \n",
    "    ets_files = os.listdir(TAR_DIR + \"entropy_ts\")\n",
    "    N_files = sorted([i for i in ets_files if (\"N0\" in i or f\"N{str(n)}\" in i) and \"eta5\" in i])\n",
    "    N_res = [pd.read_parquet(TAR_DIR + \"entropy_ts/\" + i).mean(axis = 1) for i in N_files]\n",
    "    N_df = pd.concat(N_res, axis = 1)\n",
    "    #print(N_df)\n",
    "    N_df.columns = [\"No media\"] + [str(i*10)+\"%\" for i in [1, 3, 5, 7, 9]]\n",
    "    #fig, ax = plt.subplots(1, 1)\n",
    "    cs = [\"coral\"]+colors[1:6]\n",
    "    for i, col in enumerate(N_df.columns):\n",
    "        if i ==0:\n",
    "            a = 1\n",
    "        else:\n",
    "            a = .5+(i-1)*.1\n",
    "        N_df[col].plot(color=cs[i], ax=ax, label=col, alpha = a, linewidth = a) #marker=markers[i] markersize = 5\n",
    "    ax.legend(title = \"Audience Reach\")\n",
    "    ax.set_title(f\"Num Media = {str(n)}\")\n",
    "    ax.set_ylabel(\"Entropy of opinions\")\n",
    "    ax.set_xlabel (\"Time step\")\n",
    "    ax.set_xticks([0, 2000, 4000, 6000, 8000, 10000])\n",
    "    ax.set_xticklabels([\"0\", \"2k\", \"4k\", \"6k\", \"8k\", \"10k\"])\n",
    "    if include_legend == False:\n",
    "        ax.get_legend().remove()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1_ets_files = []\n",
    "for i in range(1, 31):\n",
    "    if i in [10, 30]:\n",
    "        s = str(int(i/10))\n",
    "        N1_ets_files.append(f'N1s{s}eta5.parquet')\n",
    "    elif i == 20:\n",
    "        s = \"02\"\n",
    "        N1_ets_files.append(f'N1s{s}eta05.parquet')\n",
    "    elif i <10:\n",
    "        s = \"00\" + str(i)\n",
    "        N1_ets_files.append(f'N1s{s}eta05.parquet')\n",
    "    else:\n",
    "        s = \"0\" + str(i)\n",
    "        N1_ets_files.append(f'N1s{s}eta05.parquet')\n",
    "N1_ets_files = [\"N0s0eta5.parquet\"] + N1_ets_files\n",
    "N1_res = [pd.read_parquet(TAR_DIR + \"entropy_ts/\" + i).mean(axis = 1) for i in N1_ets_files]\n",
    "N1_df = pd.concat(N1_res, axis = 1)\n",
    "N1_df.columns = N1_df.columns = [\"No media\"] + [str(i)+\"%\" for i in range(1, 31)]\n",
    "N1_res_final = [pd.read_parquet(TAR_DIR + \"entropy_ts/\" + i).loc[\"Time_9999\"] for i in N1_ets_files]\n",
    "N1_res_final_df = pd.concat(N1_res_final, axis = 1)\n",
    "N1_res_final_df.columns =  [\"No\\nmedia\"] + [str(i) for i in range(1, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), dpi = 300)\n",
    "plot_entropy(1, ax = axes[0], include_legend= True)\n",
    "axes[0].set_title(\"A) Effects of audience reach \\n (Number of media = 1)\")\n",
    "ax = axes [1]\n",
    "sns.pointplot(N1_res_final_df, ax = ax, errwidth = 1.5)\n",
    "ax.set_ylabel(\"Entropy of final timestep\")\n",
    "ax.set_xlabel(\"Audience Reach (%)\")\n",
    "ax.set_xticks([0, 5, 10, 15, 20, 25, 30])\n",
    "ax.set_xticklabels(['No media'] + [str(i) for i in range(5, 31, 5)])\n",
    "ax.set_title(\"B) Effects of low audience reach (0 - 30%)\\n (Num Media = 1)\")\n",
    "plt.savefig(\"Entropy_one_media.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, sharex= True, sharey= True, figsize=(15, 5), dpi = 300)\n",
    "for i in range(5):\n",
    "    ax  = axes[i]\n",
    "    if i == 4:\n",
    "        plot_entropy(i+1, ax = ax, include_legend=True)\n",
    "    else:\n",
    "        plot_entropy(i+1, ax = ax)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Effects of media proliferation\", y = 1.07, fontsize = 16)\n",
    "plt.savefig(\"prolif_entropy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_op(n, s, iteration):\n",
    "    ops =[]\n",
    "    folder = f\"/N/slate/harryan/sim_data/N{str(n)}/s{str(s)}eta5\"\n",
    "    f_dir = f\"{folder}/opinions/{str(iteration)}_opinions.parquet\"\n",
    "                #print(f_dir)\n",
    "    op = pd.read_parquet(f_dir)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = get_op(1,9, 10)[\"Time_10000\"]\n",
    "hm = get_op(5,9, 3)[\"Time_10000\"]\n",
    "pl = get_op(5,9, 84)[\"Time_10000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = [hm, pl, ms]\n",
    "eg_names = [\"Homogenization\", \"Polarization\", \"Mainstreaming\"]\n",
    "colors = [\n",
    " \"#da6c42\",\n",
    " \"grey\",\n",
    " \"#225bb2\"\n",
    "]\n",
    "fig, axes = plt.subplots(1, 3, sharey = True, sharex = True, figsize = (9, 3), dpi = 300)\n",
    "axes = axes.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    sns.histplot(eg[i], ax= ax, color= colors[i], kde = True, bins = 15, alpha =.9)\n",
    "    ax.set_title(eg_names[i])\n",
    "    ax.set_xlabel(\"\")\n",
    "plt.suptitle(\"Typical final opinion distributions\", y = .92)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Typical_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_files = os.listdir(TAR_DIR + \"entropy_ts\")\n",
    "N_files = sorted([i for i in ets_files if (\"N0\" in i or \"s9\" in i) and \"eta5\" in i])\n",
    "N_res = [pd.read_parquet(TAR_DIR + \"entropy_ts/\" + i).mean(axis = 1) for i in N_files]\n",
    "N_df = pd.concat(N_res, axis = 1)\n",
    "N_df.columns = [\"No media\"] + [str(i) for i in range(1,6)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (10,6), sharey = True,  dpi = 300)\n",
    "ax = axes[0]\n",
    "cs = [\"coral\"]+colors[1:6]\n",
    "for i, col in enumerate(N_df.columns):\n",
    "    if i ==0:\n",
    "        a = 1\n",
    "    else:\n",
    "        a = .5+(i-1)*.1\n",
    "    N_df[col].plot(color=cs[i], ax=ax, label=col) #marker=markers[i] markersize = 5\n",
    "ax.legend(title = \"Number of media\", loc = \"lower left\")\n",
    "ax.set_title(f\"Entropy evolution\")\n",
    "ax.set_ylabel(\"Entropy of opinions\")\n",
    "ax.set_xlabel (\"Time step\")\n",
    "ax.set_xticks([0, 2000, 4000, 6000, 8000, 10000])\n",
    "ax.set_xticklabels([\"0\", \"2k\", \"4k\", \"6k\", \"8k\", \"10k\"])\n",
    "\n",
    "ax = axes[1]\n",
    "N90_entropies = [pd.read_parquet(TAR_DIR + \"entropy_ts/\" + i).loc[\"Time_9999\"] for i in N_files]\n",
    "N90_df_entropies = pd.concat(N90_entropies, axis = 1)\n",
    "N90_df_entropies.columns = N_df.columns\n",
    "ax, box = N90_df_entropies.boxplot(widths=0.4,\n",
    "        patch_artist=True,\n",
    "        notch=False,\n",
    "        whis=(5, 95),\n",
    "        vert=True,\n",
    "        showmeans=True,\n",
    "        return_type = \"both\", \n",
    "        positions = (1, 2, 3, 4, 5, 6),\n",
    "        figsize = (8, 8),\n",
    "        showfliers=False,\n",
    "        ax = ax)\n",
    "\n",
    "plt.setp(box['medians'], color='white', lw=1.2)\n",
    "plt.setp(box['means'], marker='o', markerfacecolor='white', markeredgecolor='white', markersize=3)\n",
    "for i, c in enumerate(cs):\n",
    "    #print(i*2,i+4)\n",
    "    plt.setp(box[\"boxes\"][i], color = c, facecolor= c, alpha = .85)\n",
    "    plt.setp(box['whiskers'][i*2:i*2 +2], lw=2.5, color = c, alpha = .8)\n",
    "    plt.setp(box['caps'][i*2:i*2 +2], lw=2.5, color = c, alpha = .8)\n",
    "ax.set_title(\"Entropy in the final time step\")\n",
    "#if include_legend == False:\n",
    "    #ax.get_legend().remove() \n",
    "plt.suptitle(\"Effects of media proliferation\\n(Audience reach = 90%)\")   \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prolif_high_reach.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_final_list = os.listdir(TAR_DIR + \"gmm_final\")\n",
    "gmm_final = [pd.read_parquet(TAR_DIR + f\"gmm_final/{file}\") for file in gmm_final_list]\n",
    "gmm_final = pd.concat(gmm_final, axis = 0)\n",
    "gmm_final = gmm_final.sort_values([\"level_0\", \"level_1\"])\n",
    "gmm_final[\"N\"] = gmm_final.level_0.str.replace(\"N\", \"\")\n",
    "gmm_final[\"s\"] = gmm_final.level_1.apply(lambda x: x[1])\n",
    "gmm_final[\"eta\"] = gmm_final.level_1.apply(lambda x: x[-1])\n",
    "gmm_final = gmm_final[gmm_final.eta != \"4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = gmm_final[gmm_final.N.isin([\"0\", \"1\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = {}\n",
    "for n in [0, 1]:\n",
    "    for s in [0, 1, 3, 5, 7, 9]:\n",
    "        cond = gmm_final[(gmm_final.N==str(n)) & (gmm_final.s==str(s))]\n",
    "        if len(cond) > 0:\n",
    "            #print(n,s)\n",
    "            count = cond[[str(i) for i in range(100)]].T.value_counts(normalize=True)\n",
    "            count.index = [t[0] for t in count.index.tolist()]\n",
    "            norm[(n,s)] = {\"2\" : count.loc[2]}\n",
    "            if 1 in count.index:\n",
    "                norm[(n,s)][\"1\"] = count.loc[1]\n",
    "            if 3 in count.index:\n",
    "                norm[(n,s)][\">2\"] = np.around(count[count.index>2].sum(),2)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi = 300)\n",
    "colors = [\n",
    " \"#da6c42\",\n",
    " \"grey\",\n",
    " \"#225bb2\"\n",
    "]\n",
    "pd.DataFrame(norm).T[[\"1\", \"2\", \">2\"]].fillna(0).plot.bar(ax = ax, color = colors, width =.8)\n",
    "ax.set_ylabel(\"Likelihood\")\n",
    "ax.legend(title = \"Optimal number of clusters\", labels = [\"Homogenization\", \"Polarization\", \"Mainstreaming\"])\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "ax.set_xticklabels([\"No media\", \"10%\", \"30%\", \"50%\", \"70%\", \"90%\"], rotation = 0)\n",
    "ax.set_xlabel(\"Audience Reach\")\n",
    "ax.set_title(\"Expected GMM clusters of final opinions\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
